KEY	YEAR	TYPE	ANNOTATION
Andrade2017	2017	m	numerical weather predictions (NWP)
Andrade2017	2017	m	gradient boosting trees
Andrade2017	2017	q	ENEWABLE energy sources (RES) are increasing steadily in several countries, mainly driven by the cost decrease of photovoltaic (PV) panels and wind turbines. 
Andrade2017	2017	a	RES variability and uncertainty introduce challenges in power system management, which requires high-quality probabilistic forecasts.
Andrade2017	2017	a	For a distribution system operator (DSO), the local variability and uncertainty may create technical problems, such as over/under-voltage and branches over-current. Therefore, accurate forecasts at the power plant level is a key requirement for this type of end-user. This information when included in 
Andrade2017	2017	a	a predictive grid management algorithm helps to [4]: (i) solve voltage problems and minimize the active power losses; (ii) maximize RES hosting capacity. 
Andrade2017	2017	o	The present paper aims at exploring information from a grid of NWP to improve RES point and probabilistic forecasting skill for a short-term time horizon (i.e., up to three days ahead). Compared to the state of the art, this is the first work to propose a framework to extract features from a NWP grid by using domain knowledge and to prove that this information can improve the forecast skill of state of the art forecasting systems. The proposed methodology constructs new variables from the raw NWP data that are used as inputs in the GBT algorithm. This results in significant improvement in point and probabilistic RES forecast. In particular, compared to reference [26] this work explores different variability features that result in higher accuracy and generalizes the framework to both wind and solar energy. Compared to reference [27], it applies a different framework (i.e., more features and a PCA by layer of variables) at the power plant level. 
Andrade2017	2017	k	short-term time horizon (i.e., up to three days ahead). 
Andrade2017	2017	o	Therefore, the use of a equally distributed grid of NWP geographical points aims to capture each site’s surrounding information in order to complement the current local information, increasing the precision and robustness of the forecasting model and decreasing both uncertainty and point forecast errors. 
Andrade2017	2017	m	weighted quantile regression model 
Andrade2017	2017	m	Gradient Boosting Trees (GBT): Gradient boosting is an ensemble machine learning algorithm that can be applied to both classifciation and regression problems. It conducts numerical optimization using steepest-descent minimization in function space by combining base learners recurrently on modified data that is the output from the previous iterations [30], [31]. GBT is a particular case of the gradient boosting algorithm where the base learners are regression trees. The additive training process can be summarized as follows: 
Andrade2017	2017	m	This algorithm has three major advantages for the RES forecasting problem: (i) non-parametric; (ii) can consider different loss functions, e.g. generate point forecasts by using the absolute or square loss and probabilistic forecasts with the quantile loss function; (iii) scalable for a high number of explanatory variables (suitable for an industrial integration). In this work, the GBT implementation from the Python opensource scikit-learn library [32] was used. 
Andrade2017	2017	h	As a thumb-rule, square root of the total number of features is a good option, which was followed and confirmed to perform well. 
Andrade2017	2017	r	Abstract—In the last two decades, renewable energy forecasting progressed towards the development of advanced physical and statistical algorithms aiming at improving point and probabilistic forecast skill. This paper describes a forecasting framework to explore information from a grid of numerical weather predictions (NWP) applied to both wind and solar energy. The methodology combines the gradient boosting trees algorithm with feature engineering techniques that extract the maximum information from the NWP grid. Compared to a model that only considers one NWP point for a specific location, the results show an average point forecast improvement (in terms of mean absolute error) of 16.09% and 12.85% for solar and wind power respectively. The probabilistic forecast improvement, in terms of continuous ranking probabilistic score, was 13.11% and 12.06% respectively. 
Andrade2017	2017	m	constrained global optimization solver1 that is built upon Bayesian techniques and Gaussian processes [29]. 
Andrade2017	2017	o	The present paper aims at exploring information from a grid of NWP to improve RES point and probabilistic forecasting skill for a short-term time horizon (i.e., up to three days ahead). Compared to the state of the art, this is the first work to propose a framework to extract features from a NWP grid by using domain knowledge and to prove that this information can improve the forecast skill of state of the art forecasting systems. The proposed methodology constructs new variables from the raw NWP data that are used as inputs in the GBT algorithm. This results in significant improvement in point and probabilistic RES forecast. In particular, compared to reference [26] this work explores different variability features that result in higher accuracy and generalizes the framework to both wind and solar energy. Compared to reference [27], it applies a different framework (i.e., more features and a PCA by layer of variables) at the power plant level. 
Andrade2017	2017	m	Continuous Ranked Probability Score (CRPS), which is a state of art metric to compare probability forecasts in the form of cumulative distribution functions. 
Yang2019a	2019	a	This is not the frist paper that aims at reconciling the practices in forecasting research. Hong and Fan12 criticized some common practices in the load forecasting literature. Solar forecasting, as another facet of energy forecasting, shares many similarities with load forecasting. Hence, their criticism mostly applies to solar forecasting. Hong and Fan’s criticism can be summarized in 5 points: 1. Many general-purpose forecasting techniques, such as an artificial neural network or exponential smoothing, have been applied to load (solar) forecasting. Once these techniques are exhausted, researchers turn to hybrid models. Although some hybrid models are useful, most do not have a long-term value.13 2. Benchmarking is necessary for a load (solar) forecasting research paper. Hence, all papers show superiority of their own techniques, using empirical studies that may not favor the benchmarking methods. This makes comparing published results difficult, and thus adds little value to load (solar) forecasting practice. 3. Since the data and code used by one group is rarely shared, the load (solar) forecasting research is often non-reproducible. 4. Some papers hide the weaknesses of the proposed methods, for example, through selecting a misleading error metric, or evaluating the forecasts over a few selected days. 5. Due to the abundance of papers and research materials available, many researchers simply cite the conclusive remarks in an unverified and misleading way, sometimes, even without reading the original paper. 
Yang2019a	2019	a	To that end, if a paper uses publicly available datasets, other researchers could replicate the results using the same data. Furthermore, if the code used to generate the forecasts is made available, i.e., making the research completely reproducible, the work should deserve more attention than a non-reproducible one. 
Yang2019a	2019	a	Next, the motivation for doing solar forecasting research needs to be clarifeid. Grid integration happens at a variety of time scales and involves a series of power system operations, and the forecast submission requirements naturally differ. However, the current solar forecasting literature only pays minimal attention on following these requirements.16 Moreover, the specifci forecasting setup—in terms of time parameters such as forecast horizon, resolution, or lead time—is often ambiguous. In order for the power system engineers to search for relevant methods from the bulky forecasting literature, the forecast setup has to be clearly stated. 
Yang2019a	2019	a	Speaking of benchmarking, the lack of a broadly accepted forecast evaluation metric is a major barrier preventing effective comparison. Since solar forecasts are data-, location-, time-step-, and horizondependent, conventional metrics such as the root-mean-square error (RMSE) cannot be used to compare forecasts made using different datasets, at different locations or horizons. The best solution to this problem at the moment is to use a forecast skill score. More specifcially, the skill score for deterministic solar forecasts needs to be calculated based on smart persistence (not simple persistence) or persistence ensemble (PeEn) for probabilistic forecasts. The reported skills should be within a reasonable range. For example, without a good reason, any forecast skill >70% is most likely due to some computational errors or at least deserves some verifciation.21 
Yang2019a	2019	a	a quick analysis on the desirable qualities of solar forecasting research, for example: 1. Is the computer code (and data) publicly available, so that the reported results can be fully reproduced? 2. Is the forecasting method operational? (The word “operational” refers to the nature of the forecasts. For example, if day-ahead forecasting is investigated, the lead time in forecast submission must be included for the paper to be considered as operational.) 3. Are the forecast probabilistic and/or physically based? (Probabilistic forecasting either generates prediction intervals or a complete predictive density. Physically based methods include NWP or remote sensing image-based forecasting; it also includes scenarios where results of physically based methods are used as part of the forecasting, e.g., analog ensemble.) 4. Is the forecasting method an ensemble? [In a weak sense, an ensemble forecasting method is anything that diversifies the forecasts, e.g., adaptive boosting, or separates the forecasting into cooperative steps, e.g., post-processing with model output statistics (MOS) can be considered as an ensemble method, see the review by Ren et al.22] 5. Are the results presented in terms of forecast skill computed from smart persistence, or skill score computed from persistence ensemble? (Smart persistence takes the clear-sky diurnal trend into consideration, thus, it is also known as clear-sky persistence, or scaled persistence. Persistence ensemble takes multiple historical data points and forms an ensemble, which can be used to benchmark probabilistic forecasts.) 
Yang2019a	2019	a	Finally, the ROPES guideline is proposed: Guideline. Solar forecasting needs to be easily Reproducible and Operational. Forecasts should be Probabilistic (and/or Physically based), produced using a non-trivial Ensemble model to minimize modeling uncertainty, and quantifeid using the forecast Skill score based on the smart persistence (or Skill score based on persistence ensemble for probabilistic forecasts), which can be directly compared to previous works. 
